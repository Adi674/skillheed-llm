# .env - Updated for Llama 3.3 70B Versatile
# RAG Chatbot Environment Configuration
# Fill in your actual API keys and URLs

# =============================================================================
# SUPABASE CONFIGURATION
# =============================================================================
# Get these from your Supabase project dashboard > Settings > API
SUPABASE_URL=https://fqymeissgxjibkzodabk.supabase.co
SUPABASE_SERVICE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImZxeW1laXNzZ3hqaWJrem9kYWJrIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc2MDM1MDYyNiwiZXhwIjoyMDc1OTI2NjI2fQ.Tu6ace3xgU9MNXmjENd6TY4KlWjsv5jWcYpDR3rdBh0

# =============================================================================
# PINECONE CONFIGURATION  
# =============================================================================
# Get these from your Pinecone dashboard
PINECONE_API_KEY=pcsk_3pinqf_Ca51ejNgpqvV9SEMQriWkBQdFFJjwy6ajds2HTraKhXDJ8f1T89PCB7qFdsVL3d
PINECONE_ENVIRONMENT=us-east1-aws
MESSAGES_INDEX_NAME=chatbot-messages
SUMMARIES_INDEX_NAME=chatbot-summaries

# =============================================================================
# GROQ CONFIGURATION - LLAMA 3.3 70B VERSATILE
# =============================================================================
# Get your API key from https://console.groq.com/
GROQ_API_KEY=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
GROQ_MODEL=llama-3.3-70b-versatile
GROQ_TEMPERATURE=0.7
GROQ_MAX_TOKENS=1024
GROQ_STREAMING=false

# Alternative Groq models (if you want to switch):
# GROQ_MODEL=llama-3.1-70b-versatile
# GROQ_MODEL=llama-3.1-8b-instant
# GROQ_MODEL=mixtral-8x7b-32768

# =============================================================================
# EMBEDDING CONFIGURATION
# =============================================================================
# Sentence Transformers model (no API key needed)
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# Alternative embedding models:
# EMBEDDING_MODEL=all-mpnet-base-v2
# EMBEDDING_DIMENSION=768

# =============================================================================
# MEMORY MANAGEMENT CONFIGURATION
# =============================================================================
# Optimized for Llama 3.3 70B's 128K context window
MAX_TOKENS_PER_SESSION=8000
CONTEXT_WINDOW_SIZE=15
SUMMARY_TRIGGER_THRESHOLD=25

# =============================================================================
# API CONFIGURATION
# =============================================================================
DEBUG=false
HOST=0.0.0.0
PORT=8000
RATE_LIMIT_PER_MINUTE=60

# =============================================================================
# LLAMA 3.3 SPECIFIC SETTINGS
# =============================================================================
LLAMA_SYSTEM_PROMPT=You are a helpful AI assistant. Provide accurate, relevant, and concise responses based on the conversation context and retrieved information.

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
LOG_LEVEL=INFO

# =============================================================================
# OPTIONAL: PERFORMANCE TUNING
# =============================================================================
# Adjust these based on your server capacity
VECTOR_SEARCH_TOP_K=5
MEMORY_SUMMARY_MAX_LENGTH=500
CONTEXT_TRUNCATION_LIMIT=50000